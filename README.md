A  lightweight GenAI workload management tool optimizes GPU utilization and job makespan, supports job scaling, GPU sharing and ensures SLA (deadline awareness/completion time) adherence, while managing diverse GenAI workloads (SDG, training, evaluation and serving) under constraints such as dynamic job arrivals, team quotas, priorities, and potential job/system failures, without relying on Kubernetes and Kueue. The detailed architecture of the first version of workload manager is available [here](images/mvp1.png)

Version 1 Features: 
- Lightweight
- GenAI aware diverse workloads
- Optimizes GPU Utilization
- Optimizes Job Makespan
- Supports Job Scaling 



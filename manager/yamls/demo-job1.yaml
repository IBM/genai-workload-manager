apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: genai-job1
  namespace: fms-tuning
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                - matchExpressions:
                  - key: nvidia.com/gpu.product
                    operator: In
                    values:
                    - NVIDIA-A100-SXM4-80GB
          containers:
          - command:
            - sh
            - -c
            - "pip install transformers==4.47\n
              echo \"Environment variables set by the kubeflow training operator:\"\necho
              \"Job name :\" ft-g8bc-4k-twittercomplaints-data\necho ${MASTER_ADDR}:${MASTER_PORT}\necho
              \"PYTHONUNBUFFERED:\"${PYTHONUNBUFFERED}\necho My global rank is ${RANK}
              / ${WORLD_SIZE}\necho \"Other injected environment variables:\"\necho
              \"NVME_MOUNT_PATH: \"${NVME_MOUNT_PATH}\n#\n# User commands\n#\necho
              executing: accelerate launch  --use_fsdp --fsdp_auto_wrap_policy=TRANSFORMER_BASED_WRAP
              --fsdp_forward_prefetch=false --fsdp_offload_params=false --fsdp_sharding_strategy=FULL_SHARD
              --fsdp_state_dict_type=FULL_STATE_DICT --fsdp_cpu_ram_efficient_loading=true
              --fsdp_sync_module_states=true --rdzv_backend=static --same_network
              --num_processes=${NGPU} --num_machines=${WORLD_SIZE} --mixed_precision=no
              --dynamo_backend=no --machine_rank=${RANK} --main_process_ip=${MASTER_ADDR}
              --main_process_port=${MASTER_PORT} -m tuning.sft_trainer \naccelerate
              launch  --use_fsdp --fsdp_auto_wrap_policy=TRANSFORMER_BASED_WRAP --fsdp_forward_prefetch=false
              --fsdp_offload_params=false --fsdp_sharding_strategy=FULL_SHARD --fsdp_state_dict_type=FULL_STATE_DICT
              --fsdp_cpu_ram_efficient_loading=true --fsdp_sync_module_states=true
              --rdzv_backend=static --same_network --num_processes=${NGPU} --num_machines=${WORLD_SIZE}
              --mixed_precision=no --dynamo_backend=no --machine_rank=${RANK} --main_process_ip=${MASTER_ADDR}
              --main_process_port=${MASTER_PORT} -m tuning.sft_trainer
              --model_name_or_path bigscience/bloom-560m
              --training_data_path /cos1/seep/tiny_llama/input.json
              --output_dir /cos1/output/sg/fine-tuned-tiny-llama-new1
              --packing false
              --response_template '\n### Response:'
              --dataset_text_field output
              --num_train_epochs 3.0
              --max_seq_length 4096
              --per_device_train_batch_size 2
              --save_strategy epoch
              --logging_steps 1
              --learning_rate 1e-5
              --use_flash_attn false
	      --trainer_controller_config_file /hfcache/seep/fms-hf-tuning/examples/trainercontroller_configs/notifier.yaml 
              --validation_data_path /hfcache/seep/fms-hf-tuning/bkp/input/validation.json 
              --metric_for_best_model 'loss' 
              --load_best_model_at_end True 
              --logging_strategy 'steps' 
              --per_device_eval_batch_size 10 
              --evaluation_strategy 'epoch'\n"
            env:
            - name: PATH
              value: /home/tuning/.local/bin:/home/tuning/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
            - name: HOME
              value: /home/tuning
            - name: HF_HOME
              value: /hfcache/.cache/huggingface
            - name: NGPU
              value: "3"
            - name: GIT_SSH_COMMAND
              value: ssh -i /tmp/.ssh/keys/id_rsa -o UserKnownHostsFile=/tmp/.ssh/hosts/known_hosts
                -vv
            image: quay.io/genai-workload-manager/sft-trainer:latest
            imagePullPolicy: Always
            name: pytorch
            resources:
              limits:
                cpu: 50
                memory: 500Gi
                nvidia.com/gpu: 4
              requests:
                cpu: 50
                memory: 500Gi
                nvidia.com/gpu: 2
            volumeMounts:
            - mountPath: /cos1
              name: cos1
            - mountPath: /hfcache
              name: hfcache
            - mountPath: /tmp/.ssh/keys
              name: private-ssh-git-deploy-key
              readOnly: true
            - mountPath: /tmp/.ssh/hosts
              name: github-known-hosts
          imagePullSecrets:
          - name: modelops-deps-pullsecret
          - name: artifactory-docker-cognitiveops
          - name: all-icr-io
          volumes:
          - name: cos1
            persistentVolumeClaim:
              claimName: my-training-cos-pvc-test1
          - name: hfcache
            persistentVolumeClaim:
              claimName: fms-tuning-pvc
          - name: private-ssh-git-deploy-key
            secret:
              optional: false
              secretName: modelops-deps-cognitiveops-ssh
          - configMap:
              name: modelops-deps-github-known-hosts
            name: github-known-hosts
